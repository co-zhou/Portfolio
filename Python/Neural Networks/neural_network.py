# -*- coding: utf-8 -*-
"""Neural_Network

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19zXi97-bXOUyvEZVuep2SlKuX-TbgiLs
"""

import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow import keras
from sklearn.metrics import confusion_matrix
from sklearn.preprocessing import normalize

labels = {"edge" : 0,
          "pass" : 1,
          "deform" : 2,
          "total_loss" : 3,
          "crack" : 4,
          "nodule" : 5
         }

inv_labels = ["edge", "pass", "deform", "total_loss", "crack", "nodule"]

def preprocessImages(x):
    return x.reshape(x.shape + (1,))/2

def preprocessLabels(y):
    out = np.zeros((y.shape[0],6))

    for i in range(len(y)):
        out[i][labels[y[i]]] = 1
    
    return out

if __name__ == "__main__":
    startX = preprocessImages(np.load("/content/drive/My Drive/ECE 157B/HW2/train_data.npy"))
    startY = preprocessLabels(np.load("/content/drive/My Drive/ECE 157B/HW2/train_label.npy"))

    s = np.arange(startX.shape[0]) 
    np.random.shuffle(s)

    X = np.empty(startX.shape)
    y = np.empty(startY.shape)

    for i in range(len(s)):
        X[s[i]] = startX[i]
        y[s[i]] = startY[i]

    percentTraining = 0.85
    trainX = X[:int(percentTraining*X.shape[0])]
    trainY = y[:int(percentTraining*y.shape[0])]
    valX = X[int(percentTraining*X.shape[0]):]
    valY = y[int(percentTraining*y.shape[0]):]

    model = keras.Sequential([
        keras.layers.Conv2D(filters=1, kernel_size=4, input_shape=(64, 64, 1)),
        keras.layers.Dense(units=64, activation='relu'),
        keras.layers.Conv2D(filters=1, kernel_size=4),
        keras.layers.Dense(units=64, activation='relu'),
        keras.layers.MaxPooling2D(),
        keras.layers.Conv2D(filters=1, kernel_size=4),
        keras.layers.Dense(units=64, activation='relu'),
        keras.layers.Conv2D(filters=1, kernel_size=3),
        keras.layers.Dense(units=64, activation='relu'),
        keras.layers.MaxPooling2D(),
        keras.layers.Flatten(),
        keras.layers.Dropout(rate=0.95),
        keras.layers.Dense(units=6, activation='softmax')
    ])

    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

    checkpoint = keras.callbacks.ModelCheckpoint(
        filepath="./saved_weight.hdf5",
        monitor='val_acc',
        verbose=1,
        save_best_only=True,
        mode='max'
    )

    callbacks_list = [checkpoint]

    history = model.fit(trainX,
              trainY,
              batch_size=17,
              epochs=128,
              verbose=1,
              validation_data=(valX, valY),
              callbacks=callbacks_list
    )

    keras.utils.plot_model(model, to_file="./model.png", show_shapes=True, expand_nested=True)
    confusion_matrix = confusion_matrix(y_true=np.argmax(valY, axis=1), y_pred=np.argmax(model.predict(valX), axis=1))
    np.save("./confusion_matrix.npy", confusion_matrix)
    print(confusion_matrix)

    plt.plot(history.history['acc'])
    plt.plot(history.history['val_acc'])
    plt.title('Model Accuracy')
    plt.ylabel('Accuracy')
    plt.xlabel('Epoch')
    plt.legend(['Train', 'Test'], loc='upper left')
    plt.savefig("./model_accuracy.png")
    plt.show()

    out = np.argmax(model.predict(preprocessImages(np.load("/content/drive/My Drive/ECE 157B/HW2/test_data.npy"))), axis=1)
    pred = []
    for i in out:
      pred.append(inv_labels[i])
    np.save("./prediction.npy", pred)